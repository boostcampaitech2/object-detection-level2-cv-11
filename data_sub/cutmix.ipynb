{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.11 64-bit ('detection': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "EfficientDet_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "29b0cbc8c2bc4924fb253dd9334aba0cc9ad3225fd824ea55dea16089b664698"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import json\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import os"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "target_cnt = 1000     # target_cnt 미만인 class들을 target_cnt 근처로 개수를 맞춰줌\n",
        "maximum_IoU = 0.3     # 합성할 때 배경 이미지의 객체들과 겹치는 허용 정도"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "random.seed(10)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "def get_file_path(json_file, image_num):\n",
        "    file_path = json_file['images'][image_num]['file_name']\n",
        "    return file_path\n",
        "\n",
        "\n",
        "def get_annotations(json_file, image_num):\n",
        "    anns = [ann['bbox'] for ann in json_file['annotations'] if ann['image_id'] == image_num]\n",
        "    return anns\n",
        "\n",
        "\n",
        "def read_image(dataset_path, file_path):\n",
        "    image = cv2.imread(dataset_path + file_path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "\n",
        "def plot_bbox(image, anns):\n",
        "    for ann in anns:\n",
        "        xmin, ymin, w, h = map(int, ann['bbox'])\n",
        "        print(xmin, ymin, w, h)\n",
        "        image = cv2.rectangle(image, (xmin, ymin), (xmin + w, ymin + h), (0, 0, 255), 3)\n",
        "    plt.imshow(image)\n",
        "\n",
        "def IoU(box1, box2):\n",
        "    # box = (x1, y1, x2, y2)\n",
        "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
        "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
        "\n",
        "    # obtain x1, y1, x2, y2 of the intersection\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    # compute the width and height of the intersection\n",
        "    w = max(0, x2 - x1 + 1)\n",
        "    h = max(0, y2 - y1 + 1)\n",
        "\n",
        "    inter = w * h\n",
        "    iou = inter / (box1_area + box2_area - inter)\n",
        "    return iou"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "os.makedirs(\"../dataset/new_train\", exist_ok=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# train 이미지들 new_train 폴더에 복사\n",
        "for img_dir in os.listdir('../dataset/train'):\n",
        "    shutil.copyfile(f\"../dataset/train/{img_dir}\", f\"../dataset/new_train/{img_dir}\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "with open('../dataset/train.json', 'r') as f:\n",
        "    train_json = json.load(f)\n",
        "dataset_path = '../dataset/'"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# train_josn의 이미지 경로 /train -> /new_train으로 바꿈\n",
        "for x, i in enumerate(train_json['images']):\n",
        "    train_json['images'][x]['file_name'] = train_json['images'][x]['file_name'].replace('train', 'new_train')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# 1000개 미만인 class들만 list로 각 클래스 별로 annotation 정보 담기\n",
        "section = [[i for i in train_json['annotations'] if i['category_id'] == j] for j in range(10)]\n",
        "low_quantity_class = [x for x, i in enumerate(section) if len(i) < target_cnt]\n",
        "low_quantity_annotations = [[i for i in train_json['annotations'] if i['category_id'] == j] for j in low_quantity_class]\n",
        "[len(i) for i in section]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3966, 6352, 897, 936, 982, 2943, 1263, 5178, 159, 468]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "for x, low_classes in enumerate(low_quantity_annotations):\n",
        "    for i in range(1000 // len(low_classes)):\n",
        "        for low_class in low_classes:\n",
        "            # 배경이미지가 5개 미만인 것이 뽑힐 때까지 랜덤으로 뽑기\n",
        "            while True:\n",
        "                background_img_num = random.randint(0, len(train_json['images'])-1)\n",
        "                background_anns = get_annotations(train_json, background_img_num)\n",
        "                if len(background_anns) < 5: break\n",
        "\n",
        "            background_img_path = get_file_path(train_json, background_img_num)\n",
        "            background_img = read_image(dataset_path, background_img_path)\n",
        "            \n",
        "            object_img_path = get_file_path(train_json, low_class['image_id'])\n",
        "            object_img = read_image(dataset_path, object_img_path)\n",
        "            object_img_bbox = map(int, low_class['bbox'])\n",
        "\n",
        "            xmin, ymin, w, h = object_img_bbox\n",
        "            object_img_cut = object_img[ymin:ymin+h, xmin:xmin+w].copy()\n",
        "\n",
        "            # 합성할 이미지와 배경이미지들의 객체의 IoU가 다 0.2 미만일 때까지 랜덤 위치 추출\n",
        "            cnt = 0\n",
        "            while True:\n",
        "                new_xmin, new_ymin = random.randint(0, 1025 - w - 1), random.randint(0, 1025 - h - 1)\n",
        "                new_box = [new_xmin, new_ymin, new_xmin+w, new_ymin+h]\n",
        "                ann = background_anns[0]\n",
        "                check = [True if IoU(new_box, [ann[0], ann[1], ann[0]+ann[2], ann[1]+ann[3]]) < maximum_IoU else False \n",
        "                        for ann in background_anns]\n",
        "                cnt += 1\n",
        "                if all(check) or cnt == 1000: break\n",
        "            if cnt == 1000: continue\n",
        "\n",
        "            # 추가한 부분 train_json의 annotations부분에 append\n",
        "            train_json['annotations'].append({\n",
        "                                \"image_id\": background_img_num,\n",
        "                                \"category_id\": low_quantity_class[x],\n",
        "                                \"area\": low_class['area'],\n",
        "                                \"bbox\": [new_xmin, new_ymin, w, h],\n",
        "                                \"iscrowd\": 0,\n",
        "                                \"id\": len(train_json['annotations'])\n",
        "                                })\n",
        "            combine_img = background_img.copy()\n",
        "            combine_img[new_ymin:new_ymin+h, new_xmin:new_xmin+w] = object_img_cut\n",
        "            # print(background_img_path) # 합성한 이미지 경로 보기\n",
        "            cv2.imwrite(os.path.join('../dataset/', background_img_path), combine_img)          "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# 수정된 train_json을 new_train.json파일로 저장\n",
        "with open('../dataset/new_train.json', 'w') as f:\n",
        "    json.dump(train_json, f, indent=\"\\t\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# 각 클래스별 개수 보기\n",
        "section = [[i for i in train_json['annotations'] if i['category_id'] == j] for j in range(10)]\n",
        "[len(i) for i in section]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3966, 6352, 1792, 1869, 1959, 2943, 1263, 5178, 1113, 1368]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "metadata": {}
    }
  ]
}