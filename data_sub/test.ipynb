{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter , defaultdict\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from objdict import ObjDict\n",
    "SEED=1234"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "file_data = OrderedDict()\n",
    "file_data['info']=OrderedDict()\n",
    "file_data['licenses']=[]\n",
    "file_data['images']=[]\n",
    "file_data['categories']=[]\n",
    "file_data['annotations']=[]\n",
    "\n",
    "val_data = OrderedDict()\n",
    "\n",
    "with open(\"/opt/ml/detection/dataset/train.json\",'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "\n",
    "file_data['info'] = json_data['info']\n",
    "file_data['licenses'] = json_data['licenses']\n",
    "file_data['categories'] = json_data['categories']\n",
    "\n",
    "val_data=deepcopy(file_data)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "for j,i in enumerate(json_data['annotations']):\n",
    "    new=[(j,i['image_id'],i['category_id'])]\n",
    "    dfnew=pd.DataFrame(new,columns=['id','image_id','category_id'])\n",
    "    df=df.append(dfnew, ignore_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "groups = df.image_id.values\n",
    "labels = df.category_id.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
    "    labels_num = np.max(y) + 1\n",
    "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "    y_distr = Counter()\n",
    "    for label, g in zip(y, groups):\n",
    "        y_counts_per_group[g][label] += 1\n",
    "        y_distr[label] += 1\n",
    "\n",
    "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "    groups_per_fold = defaultdict(set)\n",
    "    def eval_y_counts_per_fold(y_counts, fold):\n",
    "        y_counts_per_fold[fold] += y_counts\n",
    "        std_per_label = []\n",
    "        for label in range(labels_num):\n",
    "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "            std_per_label.append(label_std)\n",
    "        y_counts_per_fold[fold] -= y_counts\n",
    "        return np.mean(std_per_label)\n",
    "    \n",
    "    groups_and_y_counts = list(y_counts_per_group.items())\n",
    "    random.Random(seed).shuffle(groups_and_y_counts)\n",
    "    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k):\n",
    "            fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "            if min_eval is None or fold_eval < min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "        y_counts_per_fold[best_fold] += y_counts\n",
    "        groups_per_fold[best_fold].add(g)\n",
    "\n",
    "    all_groups = set(groups)\n",
    "    for i in range(k):\n",
    "        train_groups = all_groups - groups_per_fold[i]\n",
    "        test_groups = groups_per_fold[i]\n",
    "\n",
    "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "        yield train_indices, test_indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "splits = list(stratified_group_k_fold(df,labels,groups,k=5,seed=SEED))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[ 794. 1271.  180.  188.  197.  589.  253. 1036.   32.   94.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "    file_data['images']=[]\n",
    "    file_data['annotations']=[]\n",
    "\n",
    "    val_data['images']=[]\n",
    "    val_data['annotations']=[]\n",
    "\n",
    "    train = df.iloc[train_idx, :]  \n",
    "    valid = df.iloc[valid_idx, :]\n",
    "    \n",
    "    train_ids = train['image_id'].drop_duplicates().values\n",
    "    valid_ids = valid['image_id'].drop_duplicates().values  \n",
    "\n",
    "    for t in train_ids:\n",
    "        t=int(t)\n",
    "        file_data['images'].append(json_data['images'][t])\n",
    "    for t in train['id']:\n",
    "        file_data['annotations'].append(json_data['annotations'][t])\n",
    "\n",
    "\n",
    "    with open(tofolder+'train_fold'+str(i+1)+'.json','w',encoding=\"utf-8\") as make_file:\n",
    "        json.dump(file_data,make_file,ensure_ascii=False, indent='\\t')\n",
    "\n",
    "    for v in valid_ids:\n",
    "        v=int(v)\n",
    "        val_data['images'].append(json_data['images'][v])\n",
    "\n",
    "    for v in valid['id']:\n",
    "        val_data['annotations'].append(json_data['annotations'][v])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29b0cbc8c2bc4924fb253dd9334aba0cc9ad3225fd824ea55dea16089b664698"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('detection': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}